# Reference Image Strategy - Best Practices for 2024

## Overview

This document explains the best approach for using your own reference images that have worked well, based on current AI capabilities (2024).

## The Best Approach: Hybrid Method

**Use Direct Image References (img2img) + Style Extraction**

### Why This Works Best

1. **Direct Image References (img2img)** - Most Powerful
   - Gemini 3.0 Pro Image (via Nano Banana Pro) can use up to **14 reference images directly**
   - Images are fed directly to the AI model, not just described in text
   - Results in better character consistency, style matching, and visual coherence
   - Works like "show me something similar to these images"

2. **Style Extraction** - Enhances Prompts
   - AI analyzes your images to extract visual characteristics
   - Creates detailed style guide sections (colors, composition, lighting, etc.)
   - Enhances text prompts with learned patterns
   - Works like "describe what makes these images good"

3. **Hybrid Approach** - Best of Both Worlds
   - Use images as direct references (img2img) for visual consistency
   - Extract style to enhance prompts for better results
   - Multiple images (3-5) work better than single images

## How It Works in This System

### 1. Upload Your Reference Images

- **Upload Tab**: Upload images from your computer that have worked well
- **Favorites Tab**: Select from images you've favorited in previous projects
- **Multiple Selection**: Select up to 14 images (Gemini API limit)

### 2. Use as Direct References

When you generate new images:
- Selected reference images are sent directly to Gemini 3.0 Pro Image
- The AI sees your actual images, not just descriptions
- Results match the style, characters, and composition of your references

### 3. Extract Style (Optional)

- Click "üé® Extract Style" on selected images
- AI analyzes visual characteristics:
  - Color palette
  - Composition style
  - Lighting
  - Character design
  - Mood and tone
- Adds this to your style guide for future generations

## Best Practices

### Number of Reference Images

- **3-5 images**: Optimal for consistency without overwhelming the model
- **1-2 images**: Good for simple style matching
- **6-14 images**: Use when you need very specific character/object consistency
- **More than 14**: Not supported (Gemini API limit)

### What Images to Use

‚úÖ **Good Reference Images:**
- Images showing similar style/characters
- Images from the same project/series
- Your best-performing images
- Images with clear visual characteristics

‚ùå **Avoid:**
- Too many different styles (confuses the model)
- Low-quality or blurry images
- Images with conflicting styles

### When to Use Each Method

**Use Direct Image References (img2img) when:**
- You have specific images that worked well
- You need character consistency
- You want to match a specific visual style
- You have 3-5 similar reference images

**Use Style Extraction when:**
- You want to understand what makes your images successful
- You want to enhance your style guide
- You're building a brand style guide
- You want to improve future generations

**Use Both (Hybrid) when:**
- You want maximum consistency and quality
- You're building a brand identity
- You want the system to learn from your preferences

## Technical Details

### Current Implementation

1. **Image-to-Image (img2img)**
   - Uses Nano Banana Pro API (Gemini 3.0 Pro Image)
   - Supports up to 14 reference images
   - Images sent as base64 or URLs
   - Direct visual reference (most powerful)

2. **Style Extraction**
   - Uses Gemini API to analyze images
   - Extracts visual characteristics
   - Creates structured style guide
   - Enhances text prompts

3. **Learning System**
   - Tracks approved/favorited images
   - Analyzes what made them successful
   - Learns patterns over time
   - Improves future generations

### API Capabilities

- **Gemini 3.0 Pro Image**: Up to 14 reference images, direct img2img
- **Nano Banana Pro**: High-quality generation with image references
- **Style Analysis**: GPT-4 Vision or Gemini for style extraction

## Workflow Example

1. **Upload Your Best Images**
   - Go to "Reference Image Library"
   - Upload 3-5 images that worked well
   - Or select from favorited images

2. **Select Reference Images**
   - Click images to select them (up to 14)
   - Selected images will be used for all new generations

3. **Generate with References**
   - When generating new images, your references are automatically used
   - Results will match the style of your references

4. **Extract Style (Optional)**
   - Click "üé® Extract Style" to analyze your images
   - Style guide is enhanced with extracted characteristics
   - Future generations benefit from learned patterns

5. **Favorite Successful Images**
   - Click "‚òÜ Favorite" on images you like
   - System learns from your preferences
   - Favorited images become available as references

## Comparison: Methods

| Method | Best For | Quality | Consistency |
|--------|----------|---------|-------------|
| **Direct Image References (img2img)** | Character consistency, style matching | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Style Extraction** | Understanding patterns, enhancing prompts | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Hybrid (Both)** | Maximum quality and learning | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Text Prompts Only** | Quick generation, no references | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê |

## Conclusion

**The best approach for 2024:**
1. Upload 3-5 of your best reference images
2. Use them as direct references (img2img) - most powerful
3. Extract style to enhance prompts - improves results
4. Favorite successful images - system learns over time

This hybrid approach gives you:
- Maximum visual consistency (from direct image references)
- Better prompts (from style extraction)
- Continuous improvement (from learning system)

The system is designed to get better as you use it - the more you favorite images, the more it learns your preferences!
